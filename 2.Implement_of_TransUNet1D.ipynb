{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "class Conv1D_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=\"same\", act=True):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = int((kernel_size - 1) / 2)\n",
    "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.batchnorm = nn.BatchNorm1d(out_channels)        \n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batchnorm(out)\n",
    "        out = self.gelu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=[1, 3, 3], strides=[1, 1, 1]):\n",
    "        super().__init__()\n",
    "        self.conv1d_1 = Conv1D_block(in_channels, out_channels, kernel_size=kernel_size[0], stride=strides[0])\n",
    "        self.conv1d_2 = Conv1D_block(out_channels, out_channels, kernel_size=kernel_size[1], stride=strides[1], act=False)\n",
    "        self.conv1d_res = Conv1D_block(in_channels, out_channels, kernel_size=kernel_size[2], stride=strides[2], act=False)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1d_1(x)\n",
    "        out = self.conv1d_2(out)\n",
    "\n",
    "        shortcut = self.conv1d_res(x)\n",
    "        out += shortcut\n",
    "        out = self.gelu(out)\n",
    "        return out\n",
    "\n",
    "class UpsampleConcat_block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out = self.upsample(x1)\n",
    "        out = torch.cat([out, x2], axis=1)\n",
    "        return out\n",
    "\n",
    "class TransUNet1D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, channels=[32, 64, 128, 256], mha_latent=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.mha_latent = mha_latent\n",
    "\n",
    "        self.enc1 = Residual_block(in_channels=in_channels, out_channels=channels[0], strides=[2, 1, 2]) # in_seq_len=512,\n",
    "        self.enc2 = Residual_block(in_channels=channels[0], out_channels=channels[1], strides=[2, 1, 2]) # in_seq_len=256, \n",
    "        self.enc3 = Residual_block(in_channels=channels[1], out_channels=channels[2], strides=[2, 1, 2]) # in_seq_len=128, \n",
    "        self.enc4 = Residual_block(in_channels=channels[2], out_channels=channels[3], strides=[2, 1, 2]) # in_seq_len=64,  \n",
    "                        \n",
    "        self.dec4 = Residual_block(in_channels=channels[3],               out_channels=channels[3], strides=[1, 1, 1]) # in_seq_len=64,  \n",
    "        self.dec3 = Residual_block(in_channels=channels[2] + channels[3], out_channels=channels[2], strides=[1, 1, 1]) # in_seq_len=128, \n",
    "        self.dec2 = Residual_block(in_channels=channels[1] + channels[2], out_channels=channels[1], strides=[1, 1, 1]) # in_seq_len=256, \n",
    "        self.dec1 = Residual_block(in_channels=channels[0] + channels[1], out_channels=channels[0], strides=[1, 1, 1]) # in_seq_len=512, \n",
    "\n",
    "        self.up4 = UpsampleConcat_block()\n",
    "        self.up3 = UpsampleConcat_block()\n",
    "        self.up2 = UpsampleConcat_block()\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "        \n",
    "        self.last_conv = nn.Conv1d(in_channels=channels[0], out_channels=out_channels, kernel_size=1, stride=1) \n",
    "\n",
    "        if self.mha_latent:\n",
    "            self.d_model = channels[-1]# dimension of model\n",
    "            self.N = 6 # number of layers\n",
    "            self.h = 8 # number of heads\n",
    "            self.d_ff = 1024 # dimension of feed-forward network\n",
    "            self.P_drop = 0.1 # dropout probability\n",
    "            \n",
    "            self.mha_latent_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=self.h, dim_feedforward=self.d_ff, dropout=self.P_drop, activation=\"gelu\")\n",
    "            self.mha = nn.TransformerEncoder(self.mha_latent_layer, num_layers=self.N)\n",
    "\n",
    "    def get_positional_encoding(self, pos, i, dim):\n",
    "        angles = 1 / math.pow(10000, (2 * (i // 2))/ dim)\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            return math.sin(pos * angles)\n",
    "        return math.cos(pos * angles)\n",
    "\n",
    "    def position_encoding(self, x, seq_length):\n",
    "        pe = torch.zeros(seq_length, 1, self.d_model, device=device)\n",
    "\n",
    "        for i in range(seq_length):\n",
    "            for j in range(self.d_model):\n",
    "                pe[i, :, j] = self.get_positional_encoding(i, j, self.d_model)        \n",
    "\n",
    "        # # visualize pe\n",
    "        # plt.pcolormesh(pe[:,0],cmap='Blues')\n",
    "        # plt.xlabel('Dimension')\n",
    "        # plt.ylabel('Position')\n",
    "        \n",
    "        return pe\n",
    "        \n",
    "    def check_output_shape(self, shape):\n",
    "        x = torch.rand(shape)\n",
    "        yhat = self.forward(x)\n",
    "\n",
    "        print(f'x: {x.shape}')\n",
    "        print(f'yhat: {yhat.shape}')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3) # e4: batch, channel(d_model), seq_len\n",
    "\n",
    "        if self.mha_latent:\n",
    "            e4 = e4.permute((2,0,1)) # e4: seq_len, batch, channel(d_model)\n",
    "            pos = self.position_encoding(e4, e4.shape[0])\n",
    "            e4 += pos\n",
    "            e4 = self.mha(e4)            \n",
    "            e4 = e4.permute((1,2,0)) # e4: batch, channel(d_model), seq_len\n",
    "\n",
    "        d4 = self.dec4(e4)\n",
    "        u4 = self.up4(d4, e3)\n",
    "        \n",
    "        d3 = self.dec3(u4)\n",
    "        u3 = self.up3(d3, e2)\n",
    "        \n",
    "        d2 = self.dec2(u3)        \n",
    "        u2 = self.up2(d2, e1)\n",
    "        \n",
    "        d1 = self.dec1(u2)\n",
    "            \n",
    "        u1 = self.up1(d1)\n",
    "        out = self.last_conv(u1)\n",
    "        out = torch.softmax(out,1)\n",
    "\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransUNet1D(\n",
       "  (enc1): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(3, 32, kernel_size=(1,), stride=(2,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(3, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (enc2): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(32, 64, kernel_size=(1,), stride=(2,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (enc3): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (enc4): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (dec4): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (dec3): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(384, 128, kernel_size=(1,), stride=(1,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (dec2): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(192, 64, kernel_size=(1,), stride=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(192, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (dec1): Residual_block(\n",
       "    (conv1d_1): Conv1D_block(\n",
       "      (conv): Conv1d(96, 32, kernel_size=(1,), stride=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_2): Conv1D_block(\n",
       "      (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv1d_res): Conv1D_block(\n",
       "      (conv): Conv1d(96, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (gelu): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (gelu): GELU(approximate='none')\n",
       "  )\n",
       "  (up4): UpsampleConcat_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "  )\n",
       "  (up3): UpsampleConcat_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "  )\n",
       "  (up2): UpsampleConcat_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='linear')\n",
       "  )\n",
       "  (up1): Upsample(scale_factor=2.0, mode='linear')\n",
       "  (last_conv): Conv1d(32, 2, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = TransUNet1D(in_channels=3, out_channels=2, channels=[32, 64, 128, 256], mha_latent=False)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 3, 2048])\n",
      "yhat: torch.Size([2, 2, 2048])\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "yhat = net.check_output_shape((2,3,2048))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
